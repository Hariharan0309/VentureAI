# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Implements a session service using Google Cloud Firestore for storage.
This version uses the synchronous Firestore client to prevent event loop errors.
"""
from __future__ import annotations

import asyncio
import logging
from typing import Any, Dict, Optional

from google.cloud import firestore
from google.cloud.firestore_v1.base_query import FieldFilter
from typing_extensions import override

from google.adk.sessions import _session_util, Session
from google.adk.events.event import Event
from google.adk.events.event_actions import EventActions
from google.adk.sessions.base_session_service import (
    BaseSessionService,
    GetSessionConfig,
    ListSessionsResponse,
)

logger = logging.getLogger("google_adk." + __name__)
# Set the level to INFO to make sure our logs are captured.
logger.setLevel(logging.INFO)

SESSIONS_COLLECTION = "adk_sessions"
EVENTS_SUBCOLLECTION = "events"


class FirestoreSessionService(BaseSessionService):
    def __init__(self, project: Optional[str] = None, database: Optional[str] = None):
        """Initializes the FirestoreSessionService with the synchronous client."""
        # Use the standard synchronous client instead of the AsyncClient
        self._db = firestore.Client(project=project, database=database)

    @override
    async def create_session(
        self,
        *,
        app_name: str,
        user_id: str,
        state: Optional[dict[str, Any]] = None,
        session_id: Optional[str] = None,
    ) -> Session:
        """Creates a new session document in Firestore using a thread."""
        if session_id:
            raise ValueError("User-provided session ID is not supported.")

        def _create_in_firestore():
            session_data = {
                "app_name": app_name,
                "user_id": user_id,
                "state": state or {},
                "createTime": firestore.SERVER_TIMESTAMP,
                "updateTime": firestore.SERVER_TIMESTAMP,
            }
            # These are now synchronous calls
            _, doc_ref = self._db.collection(SESSIONS_COLLECTION).add(session_data)
            doc = doc_ref.get()
            doc_dict = doc.to_dict()
            return Session(
                app_name=doc_dict["app_name"],
                user_id=doc_dict["user_id"],
                id=doc.id,
                state=doc_dict.get("state", {}),
                last_update_time=doc_dict["updateTime"].timestamp(),
            )

        # Run the synchronous DB calls in a separate thread to not block the async server
        return await asyncio.to_thread(_create_in_firestore)

    @override
    async def get_session(
        self,
        *,
        app_name: str,
        user_id: str,
        session_id: str,
        config: Optional[GetSessionConfig] = None,
    ) -> Optional[Session]:
        """Retrieves a session and its events from Firestore using a thread."""

        def _get_from_firestore():
            session_ref = self._db.collection(SESSIONS_COLLECTION).document(session_id)
            session_doc = session_ref.get()

            if not session_doc.exists:
                return None

            session_dict = session_doc.to_dict()
            if (
                session_dict.get("app_name") != app_name
                or session_dict.get("user_id") != user_id
            ):
                return None

            update_timestamp = session_dict["updateTime"].timestamp()
            session = Session(
                app_name=session_dict["app_name"],
                user_id=session_dict["user_id"],
                id=session_doc.id,
                state=session_dict.get("state", {}),
                last_update_time=update_timestamp,
            )

            # Fetch events without ordering from the database to avoid index requirements.
            events_ref = session_ref.collection(EVENTS_SUBCOLLECTION)
            event_docs = events_ref.stream()
            events_list = [_from_firestore_doc_to_event(doc) for doc in event_docs]
            # Sort the events in the application code instead.
            events_list.sort(key=lambda e: e.timestamp)
            session.events = events_list

            if config:
                if config.num_recent_events:
                    session.events = session.events[-config.num_recent_events :]
                elif config.after_timestamp:
                    session.events = [e for e in session.events if e.timestamp > config.after_timestamp]
            
            return session

        return await asyncio.to_thread(_get_from_firestore)

    @override
    async def list_sessions(self, *, app_name: str, user_id: str) -> ListSessionsResponse:
        """Lists all sessions for a given user and app from Firestore using a thread."""
        def _list_from_firestore():
            query = self._db.collection(SESSIONS_COLLECTION).where(
                filter=FieldFilter("app_name", "==", app_name)
            ).where(filter=FieldFilter("user_id", "==", user_id))
            
            sessions = []
            for doc in query.stream():
                session_dict = doc.to_dict()
                session = Session(
                    app_name=session_dict["app_name"],
                    user_id=session_dict["user_id"],
                    id=doc.id,
                    state=session_dict.get("state", {}),
                    last_update_time=session_dict["updateTime"].timestamp(),
                )
                sessions.append(session)
            return ListSessionsResponse(sessions=sessions)

        return await asyncio.to_thread(_list_from_firestore)

    @override
    async def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:
        """Deletes a session and all its events from Firestore using a thread."""
        def _delete_in_firestore():
            session_ref = self._db.collection(SESSIONS_COLLECTION).document(session_id)
            session_doc = session_ref.get(field_paths=["app_name", "user_id"])
            if not session_doc.exists or session_doc.to_dict().get("user_id") != user_id:
                return

            events_ref = session_ref.collection(EVENTS_SUBCOLLECTION)
            event_docs = events_ref.list_documents()
            
            batch = self._db.batch()
            for doc in event_docs:
                batch.delete(doc)
            batch.delete(session_ref)
            batch.commit()
        
        await asyncio.to_thread(_delete_in_firestore)


    @override
    async def append_event(self, session: Session, event: Event) -> Event:
        """Appends an event to the session's event subcollection in Firestore using a thread."""
        await super().append_event(session=session, event=event)
        
        def _append_in_firestore():
            logger.info("Starting _append_in_firestore for session '%s'", session.id)
            try:
                # Use a batch for atomic writes.
                batch = self._db.batch()
                
                session_ref = self._db.collection(SESSIONS_COLLECTION).document(session.id)
                
                # Create a new document for the event in the subcollection.
                event_doc_ref = session_ref.collection(EVENTS_SUBCOLLECTION).document()
                event.id = event_doc_ref.id # Assign the new ID to the event object
                
                event_data_dict = _convert_event_to_json(event)
                logger.info("Appending event data: %s", event_data_dict)
                
                # Add the event creation to the batch.
                batch.set(event_doc_ref, event_data_dict)

                # Update the session document with the new state and timestamp.
                # The `session` object was already updated in memory by `super().append_event`.
                batch.update(session_ref, {
                    "updateTime": firestore.SERVER_TIMESTAMP,
                    "state": session.state
                })
                # Commit the batch.
                logger.info("Committing batch to Firestore for session '%s'...", session.id)
                batch.commit()
                logger.info("Batch committed successfully for session '%s'.", session.id)
            except Exception as e:
                # Log any exception that occurs during the process.
                logger.error(
                    "!!! Exception in _append_in_firestore for session '%s': %s",
                    session.id,
                    e,
                    exc_info=True
                )
        
        await asyncio.to_thread(_append_in_firestore)
        return event

def _convert_event_to_json(event: Event) -> Dict[str, Any]:
  """Serializes an Event object into a JSON-compatible dictionary."""
  metadata_json = {
      'partial': event.partial,
      'turn_complete': event.turn_complete,
      'interrupted': event.interrupted,
      'branch': event.branch,
      'long_running_tool_ids': (
          list(event.long_running_tool_ids)
          if event.long_running_tool_ids
          else None
      ),
  }
  if event.grounding_metadata:
    metadata_json['grounding_metadata'] = event.grounding_metadata.model_dump(
        exclude_none=True, mode='json'
    )

  event_json = {
      'author': event.author,
      'invocation_id': event.invocation_id,
      'timestamp': {
          'seconds': int(event.timestamp),
          'nanos': int(
              (event.timestamp - int(event.timestamp)) * 1_000_000_000
          ),
      },
      'error_code': event.error_code,
      'error_message': event.error_message,
      'event_metadata': metadata_json,
  }

  if event.actions:
    actions_json = {
        'skip_summarization': event.actions.skip_summarization,
        'state_delta': event.actions.state_delta,
        'artifact_delta': event.actions.artifact_delta,
        'transfer_agent': event.actions.transfer_to_agent,
        'escalate': event.actions.escalate,
        'requested_auth_configs': event.actions.requested_auth_configs,
    }
    event_json['actions'] = actions_json
  if event.content:
    event_json['content'] = event.content.model_dump(
        exclude_none=True, mode='json'
    )
  if event.error_code:
    event_json['error_code'] = event.error_code
  if event.error_message:
    event_json['error_message'] = event.error_message
  return event_json


def _from_firestore_doc_to_event(doc: firestore.DocumentSnapshot) -> Event:
  """Deserializes a Firestore document into an Event object."""
  event_dict = doc.to_dict()
  event_actions = EventActions()
  if event_dict.get('actions', None):
    actions_data = event_dict['actions']
    event_actions = EventActions(
        skip_summarization=actions_data.get('skipSummarization', None),
        state_delta=actions_data.get('stateDelta', {}),
        artifact_delta=actions_data.get('artifactDelta', {}),
        transfer_to_agent=actions_data.get('transferAgent', None),
        escalate=actions_data.get('escalate', None),
        requested_auth_configs=actions_data.get(
            'requestedAuthConfigs', {}
        ),
    )

  ts_map = event_dict['timestamp']
  timestamp_float = ts_map['seconds'] + ts_map.get('nanos', 0) / 1_000_000_000

  event = Event(
      id=doc.id,
      invocation_id=event_dict['invocation_id'],
      author=event_dict['author'],
      actions=event_actions,
      content=_session_util.decode_content(event_dict.get('content', None)),
      timestamp=timestamp_float,
      error_code=event_dict.get('error_code', None),
      error_message=event_dict.get('error_message', None),
  )

  if event_dict.get('event_metadata', None):
    metadata = event_dict['event_metadata']
    long_running_tool_ids_list = metadata.get(
        'long_running_tool_ids', None
    )
    event.partial = metadata.get('partial', None)
    event.turn_complete = metadata.get('turn_complete', None)
    event.interrupted = metadata.get('interrupted', None)
    event.branch = metadata.get('branch', None)
    event.grounding_metadata = _session_util.decode_grounding_metadata(
        metadata.get('grounding_metadata', None)
    )
    event.long_running_tool_ids = (
        set(long_running_tool_ids_list) if long_running_tool_ids_list else None
    )

  return event
